++ - добавь примеров
~~ - задание на ответ

(цифра) - примечание

Основная задача компьютерного зрения - анализ изображения через
изучение и интерпретацию его сегментов - частей изображения,
разделяемых по классам. Каждому пикселю как неделимой части
присваивается класс

Способы сегментации:

1. Бинарная. Изображение логически делится на 2 части - фон и
целевой объект. Им соответствуют 2 класса.
Пример - выделение текста с картинки в простейших задачах
фото в текст когда на однородном поле нанесен однородный текст.
Другой пример - выявление трещин и брака на поверхностях в
промышленности
++

2. Многоклассовая сегментация. Определение нескольких
взаимно исключающих классов. Подразумевает возможность формировать
иерархию классов.
Включает в себя следующие подвиды:
- семантическая
- инстанс-сегментация
- паноптическая

Пример - анализ текстового документа и выделение заголовка,
 тела, заключения и соответствующих текстов


2.1 Семантическая сегментация. Это многоклассовая сегментация
для случая, когда нам нужно выявить наличие, качество и характер, но
не количество. Объекты одного класса считаются одинаковыми.
Позволяет выстроить иерархию классов и признаков.
Пример - на фото атвопарковки можно выделить иерархию с уровнями
1 - "автомобиль", 2 - "honda"/"mercedes"/"audi",
3 - "грузовой"/"легковой", однако объекты одного класса примет
одинаковыми и не посчитает их количество
Другой пример - система автопилота, которая нацелена на
определение множества классов - дорога, пешеход, машина.
И некоторые из них могут иерархическими, к примеру дорога (знаки, встречка)
Интерсно наличие препятствий, но не их количество


2.2 Инстанс-сегментация. Это сегментация
с возможностью посчитать количесто объектов одного класса
Пример - распознавание количества людей через видеокамеру. Полезно
менеджменту магазинов в анализе их загруженности.

2.3 Паноптическая. Явно выделяет 2 объекта иерархии - фон и целевые объекты.

Пример - продвинутый анализ движения на улице. Дорога, здания, светофоры
как фон, но все равно разделимы на иерархию для событийного анализа
сцен.


С задачей сегментации лучше остальных справляются нейронки со сверточной
обработкой изображений. Прямой проход в них делится на 2 этапа и
2 структурных блока - кодировщика и декодировшика:

1. Кодировщик
        Выявление иерархии признаков. Это несколько этапов, каждый из
    которых отвечает за свой уровень иерархии и представлен
    простейшими операциями:

         - Свертка. Представление иерархии признаков в векторах
         на карте признаков. Веса фильтров свертки обучаемы
         - Активация. Как правило Relu, поскольку алгоритмически прост
          (только замена отрицательных на 0) энерго-эффективен.
         - Пулинг. Замена квадратного региона карты признаков одним
         значением - наибольшим из региона. Адаптирует модель к
         сдвигам и упрощает вычичлительную сложность алгоритма
         прямого прохода за счет уменьшения объема данных.

        Выход кодировщика - Тензор карт признаков по пикселям, отражающая
        контекст картинки - как признаки, так и связи между ними.
        Тензор имеет размер [batch, h_out, w_out, f_out] (1), где
        batch - размер входного пакета изображений,
        h_out, w_out - соответственно высота и ширина выходной карты
        признаков в пикселях. Этот размер определяется как правило
        последним блоком кодировщика и часто малого размера.
        Например [1*1]
        f_out - количество признаков на выходе из последнего блока
        кодировщика.

        Карта признаков это тензор [h_out, w_out, f_out], и она
        представляет собой матрицу пикселей, где каждому пикселю
        соответствует вектор признаков.


2. Декодировщик.

        Классификация. По карте признаков дает предсказание класса
    для каждого пикселя из карты. Отображает карту признаков на карту
    классов для каждого пикселя, приводя её размер к исходному. Пакет
    Карт классов это выход, и он является тензором
    [batch, h_in, w_in, N_classes] (1), где

    batch - количество изображений во входной выборке,
    h_in, w_in - высота и ширина изображения, равные соответственным
    размерам входного изображения из выборки,
    N_classes - количество классов, на различение которых обучена модель

    Карта классов это матрица пикселей [h_in, w_in, N_classes], где
    каждый элемент представлен one-hot вектором. Позиции векторов
    отображают истинный класс как 1, остальные обращает в 0.

    Классический проход через декодировщик состоит из таких операций:
     upscaling - пывышение разрешения карты признаков через бинарную
     интерполяцию
     skip connections - наложение карт признаков разной точности
     для лучшего предсказания и детализации
     conv/ffn layer - свертка с ядрами 1*1 или полносвязный слой для
     правильной связки признаков после upscaling/skip conn, а также
     интерпретация таких связей на нужное число признаков
     (как правило меньшее) перед следующим upscale/предсказанием
     классификация - softmax + argmax по вектору признаков каждого пикселя
     и формирование карты классов.



Примечания:

(1)

    Для обработки на GPU и CPU используются 2 разные формы тензоров,
соответственно channels-first и channels-last. В первом случае мы
определяем размеры тензора как [B, C, H, W], в втором - [B, H, W, C],
где
B - размер входящего пакета изображений (batch)
C - число каналов (признаков пикселей), channels
H, W - высота и ширина каждого изображения в пикселях

Выбор устройства зависит от 2-х параметров - объем входящих данных (V)
и (P) - интенсивность вычислений(количество циклов и итераций в них).
Можно вывести формулу device = V*P. Функция отображает две области,
и переход между ними можно выразить сигмоидой.
V и P зависят от нескольких параметров. Вот некоторые из них:

V - зависит от архитектуры памяти и в частности объемов l1/l2 кэшей.
От них зависят показатель hit rate и частота вытеснений eviction при
промахе по кешу.
P - зависит от количества ядер и частоты процессора, алгориитмической
сложности прямого и обратного проходов модели нейронки.

Большие значения определяют область GPU, меньшие - CPU.
Такое разделение связано с особенностями архитектур двух устройств.
Если вычисления просты, а объем входных данных полностью помещается в
l1/l2, достаточно будет использовать CPU device. Такие особенности как
последовательный доступ CPU к данным, а также архитектура L1/l2 с малым
объемом полностью укладываются в рамки оптимальной работы модели.
В ином случае, когда параллельная работа фильтров светки на разных ядрах
и ускорение за счет высокого hit rate l1/l2 не дают нужного эффекта,
нужно двигаться на GPU.

Когда мы используем CPU, объем входящих данных и необходимые
ресурсы процесса обработки должны помещаться полностью в кэше l1/l2.
В этом случае даже если фильтров гораздо больше ядер процессора,
мы компенсируем задержку CPU-bound за счет высокого hit rate и
отсутствия затрат на вытеснение данных из кэша(eviction).
В таких условиях удобно использовать channels-last, поскольку мы
разные фильтры помещаем на разные ядра. В рамках одного фильтра мы
можем быстро пройти по всем каналам и всем пикселям в пределах одного
канала благодаря скорости доступа в кэш.


📒📗
l1 для ядер, а l2 на CPU? способы доступа к данным - последовательный
и параллельный на GPU/CPU.
Почему channels first оптимально на gpu






📖

в классическом варианте семантической сегментации используется
структура cnn из двух компонентов - кодировщик и декодировщик.
Кодировщик как правило операциями
свертки+нормализации+пулинга+активации выявляет иерархию признаков
и помещает их контекст (признаки и связи между ними) в плоский
тензор (flatten). Задача декодировщика в том, чтобы этот контекст
распространить на все пиксели входного изображения и правильно
отобразить их классы. Решается задача через блоки
upscale+skip connections + fc/conv 1*1. На выходе получаем для
каждого изображение тензор [c, h, w], где c - количество классов,
на различение которых обучен декодировщик. Тензор выглядит как набор
 матриц, где каждая соответствует всоему классу, и отображает две
 области - фон и целевой объект в значениях пикселей 0 и 1
соответственно.

Каков смысл такого выходного тензора - где и для каких целей он
дальше используется. Покажи на этих задачах процесс обработки
тензора для получения целевого результата (Дать примеры по маске классов,
упоминая softmax, argmax)

Базовые блоки:



1. Свертка. Мозг сверточных нейронок. Все остальные блоки оптимизируют
работу сверток. Определяет Отвечает за выявление признаков, которые описывают
область изображения.


Базовые блоки:

Skip conn. Решают проблему деградации качества и детализации. Коссвенно решили проблему изчезающих градиентов.
Проблема изчезающих градиента связана с тем, что при восстановлении качества (deconv) пространство параметров аппроксимируется многомерной поверхностью некорректно. Пересечения плоскостей формируют ложние глобальные экстремумы. Наложение корректных деталей skip conn а затем интерпретация и аппроксимация параметрического пространства (через активацию/fc/conv 1*1) отображает многомерную поверхность плавнее.


FC/conv моделируют сложную зависимость между входом и выходом.
С их помощью мы ставим входные признаки в соответствие выходным.
Сложность заключается в корректной аппроксимации многомерной поверхности


dropout позволяет обучать так, чтобы прямой проход не зацикливался на одних и тех же областях многомерной поверхности. Связан с нормальным гауссовским распределением, как и  инициализация токенов и входных массивов


batch norm - удерживает распределения входов и выходов слоев в нормальных гауссовских закономерностях и определенных границах. Помогает с непредсказуемыми градиентами и плавным обучением


pooling:

3 вида, каждый по своей цели
следует менять размер окна пулинга под разные масштабы изображения?






