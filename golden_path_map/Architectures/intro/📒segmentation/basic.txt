++ - добавь примеров
~~ - задание на ответ

(цифра) - примечание

Основная задача компьютерного зрения - анализ изображения через
изучение и интерпретацию его сегментов - частей изображения,
разделяемых по классам. Каждому пикселю как неделимой части
присваивается класс

Способы сегментации:

1. Бинарная. Изображение логически делится на 2 части - фон и
целевой объект. Им соответствуют 2 класса.
Пример - выделение текста с картинки в простейших задачах
фото в текст когда на однородном поле нанесен однородный текст.
Другой пример - выявление трещин и брака на поверхностях в
промышленности
++

2. Многоклассовая сегментация. Определение нескольких
взаимно исключающих классов. Подразумевает возможность формировать
иерархию классов.
Включает в себя следующие подвиды:
- семантическая
- инстанс-сегментация
- паноптическая

Пример - анализ текстового документа и выделение заголовка,
 тела, заключения и соответствующих текстов


2.1 Семантическая сегментация. Это многоклассовая сегментация
для случая, когда нам нужно выявить наличие, качество и характер, но
не количество. Объекты одного класса считаются одинаковыми.
Позволяет выстроить иерархию классов и признаков.
Пример - на фото атвопарковки можно выделить иерархию с уровнями
1 - "автомобиль", 2 - "honda"/"mercedes"/"audi",
3 - "грузовой"/"легковой", однако объекты одного класса примет
одинаковыми и не посчитает их количество
Другой пример - система автопилота, которая нацелена на
определение множества классов - дорога, пешеход, машина.
И некоторые из них могут иерархическими, к примеру дорога (знаки, встречка)
Интерсно наличие препятствий, но не их количество


2.2 Инстанс-сегментация. Это сегментация
с возможностью посчитать количесто объектов одного класса
Пример - распознавание количества людей через видеокамеру. Полезно
менеджменту магазинов в анализе их загруженности.

2.3 Паноптическая. Явно выделяет 2 объекта иерархии - фон и целевые объекты.

Пример - продвинутый анализ движения на улице. Дорога, здания, светофоры
как фон, но все равно разделимы на иерархию для событийного анализа
сцен.


С задачей сегментации лучше остальных справляются нейронки со сверточной
обработкой изображений. Прямой проход в них делится на 2 этапа и
2 структурных блока - кодировщика и декодировшика:

1. Кодировщик
        Выявление иерархии признаков. Это несколько этапов, каждый из
    которых отвечает за свой уровень иерархии и представлен
    простейшими операциями:

         - Свертка. Представление иерархии признаков в векторах
         на карте признаков. Веса фильтров свертки обучаемы
         - Активация. Как правило Relu, поскольку алгоритмически прост
          (только замена отрицательных на 0) энерго-эффективен.
         - Пулинг. Замена квадратного региона карты признаков одним
         значением - наибольшим из региона. Адаптирует модель к
         сдвигам и упрощает вычичлительную сложность алгоритма
         прямого прохода за счет уменьшения объема данных.

        Выход кодировщика - Тензор карт признаков по пикселям, отражающая
        контекст картинки - как признаки, так и связи между ними.
        Тензор имеет размер [batch, h_out, w_out, f_out] (1), где
        batch - размер входного пакета изображений,
        h_out, w_out - соответственно высота и ширина выходной карты
        признаков в пикселях. Этот размер определяется как правило
        последним блоком кодировщика и часто малого размера.
        Например [1*1]
        f_out - количество признаков на выходе из последнего блока
        кодировщика.

        Карта признаков это тензор [h_out, w_out, f_out], и она
        представляет собой матрицу пикселей, где каждому пикселю
        соответствует вектор признаков.


2. Декодировщик.

        Классификация. По карте признаков дает предсказание класса
    для каждого пикселя из карты. Отображает карту признаков на карту
    классов для каждого пикселя, приводя её размер к исходному. Пакет
    Карт классов это выход, и он является тензором
    [batch, h_in, w_in, N_classes] (1), где

    batch - количество изображений во входной выборке,
    h_in, w_in - высота и ширина изображения, равные соответственным
    размерам входного изображения из выборки,
    N_classes - количество классов, на различение которых обучена модель

    Карта классов это матрица пикселей [h_in, w_in, N_classes], где
    каждый элемент представлен one-hot вектором. Позиции векторов
    отображают истинный класс как 1, остальные обращает в 0.

    Классический проход через декодировщик состоит из таких операций:
     upscaling - пывышение разрешения карты признаков через бинарную
     интерполяцию
     skip connections - наложение карт признаков разной точности
     для лучшего предсказания и детализации
     conv/ffn layer - свертка с ядрами 1*1 или полносвязный слой для
     правильной связки признаков после upscaling/skip conn, а также
     интерпретация таких связей на нужное число признаков
     (как правило меньшее) перед следующим upscale/предсказанием
     классификация - softmax + argmax по вектору признаков каждого пикселя
     и формирование карты классов.



Примечания:

(1)

    Для обработки на GPU и CPU используются 2 разные формы тензоров,
соответственно channels-first и channels-last. В первом случае мы
определяем размеры тензора как [B, C, H, W], в втором - [B, H, W, C],
где
B - размер входящего пакета изображений (batch)
C - число каналов (признаков пикселей), channels
H, W - высота и ширина каждого изображения в пикселях

Выбор устройства зависит от 2-х параметров - объем входящих данных (V)
и (P) - интенсивность вычислений(количество циклов и итераций в них).
Можно вывести формулу device = V*P. Функция отображает две области,
и переход между ними можно выразить сигмоидой.
V и P зависят от нескольких параметров. Вот некоторые из них:

V - зависит от архитектуры памяти и в частности объемов l1/l2 кэшей.
От них зависят показатель hit rate и частота вытеснений eviction при
промахе по кешу.
P - зависит от количества ядер и частоты процессора, алгориитмической
сложности прямого и обратного проходов модели нейронки.

Большие значения определяют область GPU, меньшие - CPU.
Такое разделение связано с особенностями архитектур двух устройств.
Если вычисления просты, а объем входных данных полностью помещается в
l1/l2, достаточно будет использовать CPU device. Такие особенности как
последовательный доступ CPU к данным, а также архитектура L1/l2 с малым
объемом полностью укладываются в рамки оптимальной работы модели.
В ином случае, когда параллельная работа фильтров светки на разных ядрах
и ускорение за счет высокого hit rate l1/l2 не дают нужного эффекта,
нужно двигаться на GPU.

Когда мы используем CPU, объем входящих данных и необходимые
ресурсы процесса обработки должны помещаться полностью в кэше l1/l2.
В этом случае даже если фильтров гораздо больше ядер процессора,
мы компенсируем задержку CPU-bound за счет высокого hit rate и
отсутствия затрат на вытеснение данных из кэша(eviction).
В таких условиях удобно использовать channels-last, поскольку мы
разные фильтры помещаем на разные ядра. В рамках одного фильтра мы
можем быстро пройти по всем каналам и всем пикселям в пределах одного
канала благодаря скорости доступа в кэш.


📒📗
l1 для ядер, а l2 на CPU? способы доступа к данным - последовательный
и параллельный на GPU/CPU.
Почему channels first оптимально на gpu






Базовые блоки:

1. Свертка. Мозг сверточных нейронок. Все остальные блоки оптимизируют
работу сверток. Определяет Отвечает за выявление признаков, которые описывают
область изображения.




После базовых блоков:

С примерами:

Выход модели — вероятности (после softmax), не one-hot (one-hot —
это формат ground truth для обучения; модель выдаёт soft
probabilities, argmax даёт классы).
Размер — обычно [B, N_classes, H, W] (каналы=классы first в
PyTorch для softmax).
Исправление/уточнение: Выход — тензор вероятностей [B, N_classes,
H_in, W_in]; argmax по каналам даёт маску [B, 1, H_in, W_in] с
классовыми ID. One-hot — для labels в loss (categorical
cross-entropy). Пример: Для N_classes=3, пиксель с вероятностями
[0.1, 0.8, 0.1] → argmax=1 (класс 1).





